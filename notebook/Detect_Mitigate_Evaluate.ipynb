{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to use asynchronous functions or methods in jupyter notebook\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "# allows using the running event loop\n",
    "import asyncio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mitigation via Completion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schema Definations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "## defining function schemas\n",
    "\n",
    "from typing import Union, Literal\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "# NonToolAnswer schema will be used for verifying the output\n",
    "class NonToolAnswer(BaseModel):\n",
    "    answer: str\n",
    "\n",
    "\n",
    "avaialle_non_tool_answering = [{\n",
    "    \"name\": \"Answer\",\n",
    "    \"description\": \"Answer the user message without being verbose.\",\n",
    "    \"parameters\": NonToolAnswer.model_json_schema(),\n",
    "}]\n",
    "\n",
    "function_names = [\n",
    "    \"Answer\",\n",
    "    \"MakeCall\",\n",
    "    \"CallInteraction\",\n",
    "    \"SendMessage\",\n",
    "    \"AudioInteraction\",\n",
    "    \"MapInteraction\",\n",
    "]\n",
    "\n",
    "\n",
    "class SearchTool(BaseModel):\n",
    "    q: str = Field(..., description=\"Search Query.\")\n",
    "\n",
    "\n",
    "class UseContact(BaseModel):\n",
    "    is_number: bool = Field(\n",
    "        ...,\n",
    "        description=\n",
    "        \"True if a number is specified by the user and False if the user provides contact name.\",\n",
    "    )\n",
    "    number: Union[str, None] = Field(\n",
    "        ..., description=\"The number if provided by the user else None.\")\n",
    "    contact_name: Union[str, None] = Field(\n",
    "        ...,\n",
    "        description=\n",
    "        \"If a number is not provided the user will provide the name of the contact to call.\",\n",
    "    )\n",
    "\n",
    "\n",
    "class MakeCall(BaseModel):\n",
    "    app_name: Literal[\"Phone\", \"WhatsApp\"] = Field(\n",
    "        default=\"Phone\",\n",
    "        description=\"Specify the application name provided by the user.\",\n",
    "    )\n",
    "    meta: UseContact\n",
    "\n",
    "\n",
    "class CallInteraction(BaseModel):\n",
    "    interaction_type: Literal[\"ACCEPT\", \"REJECT\"] = Field(\n",
    "        ..., description=\"The user can ask to accept or reject the call.\")\n",
    "\n",
    "\n",
    "class SendMessage(BaseModel):\n",
    "    app_name: Literal[\"Phone\", \"WhatsApp\"] = Field(\n",
    "        default=\"Phone\",\n",
    "        description=\"Specify the application name provided by the user.\",\n",
    "    )\n",
    "    meta: UseContact\n",
    "    message_text: str = Field(\n",
    "        ..., description=\"The message the user wants to send.\")\n",
    "\n",
    "\n",
    "class AudioInteraction(BaseModel):\n",
    "    action: Literal[\"Select\", \"Play\", \"Pause\"] = Field(\n",
    "        ...,\n",
    "        description=\n",
    "        \"The user can either select a song to play, pause a song, or play a paused song\",\n",
    "    )\n",
    "    is_select: bool = Field(\n",
    "        ..., description=\"True if a user is asking to play a specific song.\")\n",
    "    song_name: Union[str, None] = Field(\n",
    "        ...,\n",
    "        description=\"Name of the song in case `is_select` is true else None.\")\n",
    "\n",
    "\n",
    "class Stop(BaseModel):\n",
    "    action: Literal[\"Add\", \"Remove\"] = Field(\n",
    "        ..., description=\"The user can ask to add or remove a stop.\")\n",
    "    name: str = Field(..., description=\"Name of the stop.\")\n",
    "\n",
    "\n",
    "class MapInteraction(BaseModel):\n",
    "    action: Literal[\"Start\", \"Update\"] = Field(\n",
    "        ...,\n",
    "        description=\n",
    "        \"The user can start the map action by saying where they want to go. Or else they can provide an update to add or remove a stop.\",\n",
    "    )\n",
    "    is_update: bool = Field(\n",
    "        ...,\n",
    "        description=\n",
    "        \"If the user is asking to add or remove a stop then it's update.\",\n",
    "    )\n",
    "    stop: Union[Stop, None] = Field(\n",
    "        ...,\n",
    "        description=\n",
    "        \"The stop details are required if `is_update` is true else it can be None\",\n",
    "    )\n",
    "\n",
    "\n",
    "available_domain_specific_tools = [\n",
    "    {\n",
    "        \"name\": \"MakeCall\",\n",
    "        \"description\": \"Used to make a call.\",\n",
    "        \"parameters\": MakeCall.model_json_schema(),\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"CallInteraction\",\n",
    "        \"description\": \"Used to interact with an incoming call.\",\n",
    "        \"parameters\": CallInteraction.model_json_schema(),\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"SendMessage\",\n",
    "        \"description\": \"Used to send a message.\",\n",
    "        \"parameters\": SendMessage.model_json_schema(),\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"AudioInteraction\",\n",
    "        \"description\":\n",
    "        \"Used to interact with audio system like select music, pause music, or play a paused music\",\n",
    "        \"parameters\": AudioInteraction.model_json_schema(),\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"MapInteraction\",\n",
    "        \"description\": \"Used to set or update location in the map\",\n",
    "        \"parameters\": MapInteraction.model_json_schema(),\n",
    "    },\n",
    "]\n",
    "\n",
    "available_search_tool_functions = [{\n",
    "    \"name\":\n",
    "    \"Search\",\n",
    "    \"description\":\n",
    "    \"Search for the user query\",\n",
    "    \"parameters\":\n",
    "    SearchTool.model_json_schema(),\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM Completion Utilities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Context Management with Sliding Window\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "from typing import List, Dict\n",
    "\n",
    "\n",
    "class MessageManagement:\n",
    "    \"\"\"Removes tokens from start or end and provides string with max token lenght provided\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str = \"gpt-4-turbo-preview\",\n",
    "        encoding_name: Union[str, None] = None,\n",
    "    ):\n",
    "        try:\n",
    "            self.encoding = tiktoken.encoding_for_model(model_name)\n",
    "        except KeyError:\n",
    "            self.encoding = tiktoken.get_encoding(encoding_name)\n",
    "\n",
    "    def __count_tokens__(self, content: str):\n",
    "        tokens = self.encoding.encode(content)\n",
    "        return len(tokens) + 4\n",
    "\n",
    "    def __pad_message__(self, content: str, num_tokens: int):\n",
    "        tokens = self.encoding.encode(content)\n",
    "        return self.encoding.decode(tokens[:num_tokens])\n",
    "\n",
    "    def __call__(self, messages: List[Dict], max_length: int = 14_000):\n",
    "        system_prompt = list(\n",
    "            filter(lambda message: message.get(\"role\") == \"system\", messages))\n",
    "        other_messages = list(\n",
    "            filter(lambda message: message.get(\"role\") != \"system\", messages))\n",
    "\n",
    "        managed_messages = []\n",
    "\n",
    "        curr_length = 0\n",
    "        if len(system_prompt) == 1:\n",
    "            curr_length += self.__count_tokens__(\n",
    "                system_prompt[0].get(\"content\"))\n",
    "        for message in other_messages[::-1]:\n",
    "            if message.get(\"role\") == \"system\":\n",
    "                managed_messages += message\n",
    "            else:\n",
    "                lgth = self.__count_tokens__(message.get(\"content\"))\n",
    "                if curr_length + lgth >= max_length:\n",
    "                    tokens_to_keep = max_length - curr_length\n",
    "                    # print(f\"TOKENS TO KEEP: \", tokens_to_keep)\n",
    "                    if tokens_to_keep > 0:\n",
    "                        padded_message = self.__pad_message__(\n",
    "                            message.get(\"content\"), tokens_to_keep)\n",
    "                        message[\"content\"] = padded_message\n",
    "                        managed_messages.append(message)\n",
    "                        curr_length += tokens_to_keep\n",
    "                        break\n",
    "                    else:\n",
    "                        break\n",
    "                else:\n",
    "                    managed_messages.append(message)\n",
    "                    curr_length += lgth\n",
    "        managed_messages = system_prompt + managed_messages[::-1]\n",
    "        return managed_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"YOUR OPENAI API KEY\"\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import List, Dict, Union\n",
    "from openai import AsyncOpenAI, RateLimitError, APIConnectionError\n",
    "import backoff\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class BaseLLM(ABC):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        self.client = None\n",
    "\n",
    "    @abstractmethod\n",
    "    async def __complete__(self, messages: List[Dict], model: str, **kwargs):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    async def __stream__(self, messages: List[Dict], model: str, **kwargs):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    async def __function_call__(self, messages: List[Dict], model: str,\n",
    "                                **kwargs):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "FUNCTION_CALLING_SYSTEM_PROMPT = \"\"\"You are a helpful assistant with access to the following functions:\n",
    "\n",
    "    {functions}\n",
    "\n",
    "    To use these functions respond with:\n",
    "    <multiplefunctions>\n",
    "        <functioncall> {{fn}} </functioncall>\n",
    "        <functioncall> {{fn}} </functioncall>\n",
    "        ...\n",
    "    </multiplefunctions>\n",
    "\n",
    "    Edge cases you must handle:\n",
    "    - If there are no functions that match the user request, you will respond politely that you cannot help.<|im_end|>\n",
    "\n",
    "    Refer the below provided output example for function calling\n",
    "    Question: What's the weather difference in NY and LA?\n",
    "    <multiplefunctions>\n",
    "        <functioncall> {{\"name\": \"getWeather\", \"parameters\": {{\"city\": \"NY\"}}}} </functioncall>\n",
    "        <functioncall> {{\"name\": \"getWeather\", \"parameters\": {{\"city\": \"LA\"}}}} </functioncall>\n",
    "    </multiplefunctions>\n",
    "\n",
    "    Note: You can even select only <functioncall> inside <multiplefunctions> block if needed.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import logging\n",
    "from xml.etree import ElementTree as ET\n",
    "\n",
    "\n",
    "def extractUsingRegEx(output_text: str):\n",
    "    pattern = r\"<functioncall>\\s*(\\{.*?\\})\\s*</functioncall>\"\n",
    "    matches = re.findall(pattern, output_text, re.DOTALL)\n",
    "    logging.info(f\"Exception block Matches: {matches}\")\n",
    "\n",
    "    results = []\n",
    "    for json_string in matches:\n",
    "        try:\n",
    "            json_data = json.loads(json_string)\n",
    "            results.append(json_data)\n",
    "        except json.JSONDecodeError as err:\n",
    "            print(f\"Error decoding JSON: {str(err)}\")\n",
    "            continue\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpenAILLM(BaseLLM):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        self.client = AsyncOpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "        self.ctx = MessageManagement(kwargs.get(\"model\"),\n",
    "                                     kwargs.get(\"encoding_name\", None))\n",
    "\n",
    "    async def __complete__(self, messages: List[Dict], model: str, **kwargs):\n",
    "        managed_messages = self.ctx(messages, 110_000)\n",
    "        output = await self.client.chat.completions.create(\n",
    "            messages=managed_messages, model=model, **kwargs)\n",
    "        usage = output.usage.__dict__\n",
    "        output_content = output.choices[0].message.content\n",
    "        if \"logprobs\" in kwargs:\n",
    "            return (\n",
    "                output_content,\n",
    "                output.choices[0].logprobs.content[0].top_logprobs,\n",
    "                usage,\n",
    "            )\n",
    "        return output_content, None, usage\n",
    "\n",
    "    async def __stream__(self, messages: List[Dict], model: str, **kwargs):\n",
    "        managed_messages = self.ctx(messages, 110_000)\n",
    "        stream = await self.client.chat.completions.create(\n",
    "            model=model, messages=managed_messages, stream=True, **kwargs)\n",
    "        async for chunk in stream:\n",
    "            yield chunk.choices[0].delta.content or \"\"\n",
    "\n",
    "    async def __function_call__(self, messages: List[Dict], model: str,\n",
    "                                tools: List[Dict], **kwargs):\n",
    "        system_message = list(\n",
    "            filter(lambda message: message.get(\"role\") == \"system\", messages))\n",
    "        if len(system_message) > 0:\n",
    "            system_message = system_message[0]\n",
    "            system_message[\"content\"] = (\n",
    "                FUNCTION_CALLING_SYSTEM_PROMPT.format(functions=tools) +\n",
    "                \"\\n\\n\" + \"Task: \" + \"\\n\\n\" + system_message.get(\"content\"))\n",
    "\n",
    "        else:\n",
    "            system_message = {\n",
    "                \"role\": \"system\",\n",
    "                \"content\":\n",
    "                FUNCTION_CALLING_SYSTEM_PROMPT.format(functions=tools),\n",
    "            }\n",
    "        non_system_messages = list(\n",
    "            filter(lambda message: message.get(\"role\") != \"system\", messages))\n",
    "        messages = [system_message] + non_system_messages\n",
    "        output_content, _, usage = await self.__complete__(messages, model)\n",
    "        function_calls = extractUsingRegEx(output_content)\n",
    "        if function_calls:\n",
    "            return True, function_calls, usage\n",
    "        print(f\"OUTPUT CONTENT: \", output_content)\n",
    "        return False, output_content, usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example Interaction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": \"I want to call my Mom\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAILLM(model=\"gpt-4o\", encoding_name=\"o200k_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTPUT CONTENT:  Which app would you like to use to call your Mom, Phone or WhatsApp?\n",
      "(False, 'Which app would you like to use to call your Mom, Phone or WhatsApp?', {'completion_tokens': 17, 'prompt_tokens': 1368, 'total_tokens': 1385})\n"
     ]
    }
   ],
   "source": [
    "output = asyncio.run(\n",
    "    llm.__function_call__(messages, \"gpt-4o\", available_domain_specific_tools))\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(True, [{'name': 'MakeCall', 'parameters': {'app_name': 'Phone', 'meta': {'is_number': False, 'number': None, 'contact_name': 'Mom'}}}], {'completion_tokens': 58, 'prompt_tokens': 1404, 'total_tokens': 1462})\n"
     ]
    }
   ],
   "source": [
    "messages.append({\"role\": \"assistant\", \"content\": output[1]})\n",
    "messages.append({\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"Contact name is 'Mom' and call her using Phone\"\n",
    "})\n",
    "output = asyncio.run(\n",
    "    llm.__function_call__(messages, \"gpt-4o\", available_domain_specific_tools))\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mitigation Layers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inherent knowledge verification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAN_ANSWER_WITH_INHERENT_KNOWLEDGE = \"\"\"You are a helpful assistant as part of car infotainment system. The driver or passengers can ask you to perform specific tasks or can ask you about certain things.\n",
    "Based on the what they are asking you have to decide if you can answer that directly or not. You just have to reply with a YES or NO and nothing else.\n",
    "When a user asks for specific tasks like calling someone, playing music, setting up navigation, etc. which you cannot do directly you should reply with NO.\n",
    "You only have the world knowledge up until October of 2023. You don't have any current affairs knowledge about October 2023.\n",
    "Today's date is {date} (dd-mm-yyyy).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSIFICATION_THRESHOLD = 0.82\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def calculateLinearProbability(logprob):\n",
    "    return np.round(np.exp(logprob.logprob) * 100)\n",
    "\n",
    "\n",
    "async def canUseInherentKnowledge(llm: BaseLLM, model: str,\n",
    "                                  messages: List[Dict]):\n",
    "    messages = [{\n",
    "        \"role\":\n",
    "        \"system\",\n",
    "        \"content\":\n",
    "        CAN_ANSWER_WITH_INHERENT_KNOWLEDGE.format(\n",
    "            date=datetime.today().strftime(\"%d-%m-%Y\")),\n",
    "    }] + messages\n",
    "    output = await llm.__complete__(messages,\n",
    "                                    model,\n",
    "                                    logprobs=True,\n",
    "                                    top_logprobs=1,\n",
    "                                    seed=42,\n",
    "                                    temperature=0.2)\n",
    "    # print(output)\n",
    "    output_label, logprobs, usage = output\n",
    "    linear_probability = calculateLinearProbability(logprobs[0])\n",
    "    if linear_probability > CLASSIFICATION_THRESHOLD:\n",
    "        return output_label, usage\n",
    "    return None, usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('YES', [TopLogprob(token='YES', bytes=[89, 69, 83], logprob=-0.00012035091)], {'completion_tokens': 1, 'prompt_tokens': 166, 'total_tokens': 167})\n",
      "('YES', {'completion_tokens': 1, 'prompt_tokens': 166, 'total_tokens': 167})\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    asyncio.run(\n",
    "        canUseInherentKnowledge(\n",
    "            llm,\n",
    "            \"gpt-4o\",\n",
    "            [{\n",
    "                \"role\":\n",
    "                \"user\",\n",
    "                \"content\":\n",
    "                \"Which team won the FIFA 2022 world cup and who was the captain?\",\n",
    "            }],\n",
    "        )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('NO', [TopLogprob(token='NO', bytes=[78, 79], logprob=-0.004088728)], {'completion_tokens': 1, 'prompt_tokens': 159, 'total_tokens': 160})\n",
      "('NO', {'completion_tokens': 1, 'prompt_tokens': 159, 'total_tokens': 160})\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    asyncio.run(\n",
    "        canUseInherentKnowledge(\n",
    "            llm,\n",
    "            \"gpt-4o\",\n",
    "            [{\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Who's the current captain of Indian cricket team?\",\n",
    "            }],\n",
    "        )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('NO', [TopLogprob(token='NO', bytes=[78, 79], logprob=-2.220075e-06)], {'completion_tokens': 1, 'prompt_tokens': 153, 'total_tokens': 154})\n",
      "('NO', {'completion_tokens': 1, 'prompt_tokens': 153, 'total_tokens': 154})\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    asyncio.run(\n",
    "        canUseInherentKnowledge(llm, \"gpt-4o\", [{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Call my mom\"\n",
    "        }])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answering with Inherent knowledge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANSWER_WITH_INHERENT_KNOWLEDGE_PROMPT = \"\"\"You are a helpful assistant as part of car infotainment system. You have to answer the user's generic questions or queries in the format mentioned in the function schema.\"\"\"\n",
    "\n",
    "\n",
    "async def answerWithInherentKnowledge(llm: BaseLLM, model: str,\n",
    "                                      messages: List[Dict]):\n",
    "    messages = [{\n",
    "        \"role\": \"system\",\n",
    "        \"content\": ANSWER_WITH_INHERENT_KNOWLEDGE_PROMPT\n",
    "    }] + messages\n",
    "    function_call_available, function_call, usage = await llm.__function_call__(\n",
    "        messages, model, avaialle_non_tool_answering, seed=42, temperature=0.2)\n",
    "    if function_call_available:\n",
    "        return function_call, usage\n",
    "    return None, usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([{'name': 'Answer', 'parameters': {'answer': 'Argentina won the FIFA 2022 World Cup, and the captain was Lionel Messi.'}}], {'completion_tokens': 40, 'prompt_tokens': 319, 'total_tokens': 359})\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    asyncio.run(\n",
    "        answerWithInherentKnowledge(\n",
    "            llm,\n",
    "            \"gpt-4o\",\n",
    "            [{\n",
    "                \"role\":\n",
    "                \"user\",\n",
    "                \"content\":\n",
    "                \"Which team won the FIFA 2022 world cup and who was the captain?\",\n",
    "            }],\n",
    "        )))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search Tool Check and Search functionality\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERIFY_SEARCH_TOOL_NEEDED = \"\"\"You are a helpful assistant as part of car infotainment system. The driver or passengers can ask you to perform specific tasks or can ask you about certain things.\n",
    "Based on the what they are asking you have to decide if you can answer that directly or not. You just have to reply with a YES or NO and nothing else.\n",
    "When a user asks for specific tasks like calling someone, playing music, setting up navigation, etc. which you cannot do directly you should reply with NO.\n",
    "Only if the task requires searching the web you have to reply with YES.\n",
    "You only have the world knowledge up until October of 2023. \n",
    "You don't have any current affairs knowledge about October 2023. You need to search for events after October 2023.\n",
    "Today's date is {date} (dd-mm-yyyy).\"\"\"\n",
    "\n",
    "\n",
    "async def verifySearchRequired(llm: BaseLLM, model: str, messages: List[Dict]):\n",
    "    messages = [{\n",
    "        \"role\":\n",
    "        \"system\",\n",
    "        \"content\":\n",
    "        VERIFY_SEARCH_TOOL_NEEDED.format(\n",
    "            date=datetime.today().strftime(\"%d-%m-%Y\")),\n",
    "    }] + messages\n",
    "    output = await llm.__complete__(messages,\n",
    "                                    model,\n",
    "                                    logprobs=True,\n",
    "                                    top_logprobs=1,\n",
    "                                    seed=42,\n",
    "                                    temperature=0.2)\n",
    "    output_label, logprobs, usage = output\n",
    "    # print(f\"SEARCH REQUIRED LABEL: \", output_label)\n",
    "    linear_probability = calculateLinearProbability(logprobs[0])\n",
    "    if linear_probability > CLASSIFICATION_THRESHOLD:\n",
    "        return output_label, usage\n",
    "    return None, usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEARCH REQUIRED LABEL:  YES\n",
      "('YES', {'completion_tokens': 1, 'prompt_tokens': 187, 'total_tokens': 188})\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    asyncio.run(\n",
    "        verifySearchRequired(\n",
    "            llm,\n",
    "            \"gpt-4o\",\n",
    "            [{\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Where can I eat Chinese food near me?\"\n",
    "            }],\n",
    "        )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEARCH REQUIRED LABEL:  NO\n",
      "('NO', {'completion_tokens': 1, 'prompt_tokens': 181, 'total_tokens': 182})\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    asyncio.run(\n",
    "        verifySearchRequired(llm, \"gpt-4o\", [{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Call my mom\"\n",
    "        }])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEARCH REQUIRED LABEL:  NO\n",
      "('NO', {'completion_tokens': 1, 'prompt_tokens': 181, 'total_tokens': 182})\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    asyncio.run(\n",
    "        verifySearchRequired(llm, \"gpt-4o\", [{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Navigate to Home\"\n",
    "        }])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEARCH REQUIRED LABEL:  YES\n",
      "('YES', {'completion_tokens': 1, 'prompt_tokens': 184, 'total_tokens': 185})\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    asyncio.run(\n",
    "        verifySearchRequired(llm, \"gpt-4o\",\n",
    "                             [{\n",
    "                                 \"role\": \"user\",\n",
    "                                 \"content\": \"Who won the Superbowl?\"\n",
    "                             }])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Brave Search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "\n",
    "os.environ[\"BRAVE_API_KEY\"] = \"YOUR BRAVE API KEY\"\n",
    "\n",
    "BRAVE_API_KEY = os.environ.get(\"BRAVE_API_KEY\")\n",
    "\n",
    "\n",
    "async def brave_search(search_term):\n",
    "    brave_api_key = BRAVE_API_KEY\n",
    "    url = f\"https://api.search.brave.com/res/v1/web/search?q={search_term}&count=3\"\n",
    "    headers = {\n",
    "        \"X-Subscription-Token\": brave_api_key,\n",
    "        \"Accept\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    async with httpx.AsyncClient() as client:\n",
    "        response = await client.get(url, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            # print('Search Data: ', data)\n",
    "            return format_search(data)\n",
    "        print(await response.text())\n",
    "        return None\n",
    "\n",
    "\n",
    "def format_search(search_results):\n",
    "    retrieve_keys = [\"web\", \"news\"]\n",
    "    formatted_results = []\n",
    "    for value in retrieve_keys:\n",
    "        if value in search_results:\n",
    "            results = search_results[value][\"results\"]\n",
    "            formatted_results.append(\"\\n\".join(\n",
    "                f\"Title: {result['title']} Description: {result['description']} URL: {result['url']}\"\n",
    "                for result in results))\n",
    "    # print('Formatted Results: ', formatted_results)\n",
    "    if formatted_results:\n",
    "        return \"\\n\".join(formatted_results)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEARCH_RESPONSE_PROMPT = \"\"\"You are a helpful assistant as part of car infotainment system. You are provided with a set of search results in triple backticks based on that you have to answer for the user question without being verbose in the function schema defined.\"\"\"\n",
    "\n",
    "\n",
    "async def searchGenAnswer(llm: BaseLLM, model: str, messages: List[Dict]):\n",
    "    search_query = messages[-1].get(\"content\")\n",
    "    search_results = await brave_search(search_query)\n",
    "    if not search_results:\n",
    "        return False, \"Unable to search! Please try again later!\"\n",
    "    messages[-1][\"content\"] += (\"\\n\\n\" + \"Search results: \" + \"\\n\" +\n",
    "                                f\"```{search_results}```\")\n",
    "    messages = [{\n",
    "        \"role\": \"system\",\n",
    "        \"content\": SEARCH_RESPONSE_PROMPT\n",
    "    }] + messages\n",
    "    function_call_available, function_call, usage = await llm.__function_call__(\n",
    "        messages, model, avaialle_non_tool_answering, seed=42, temperature=0.2)\n",
    "    if function_call_available:\n",
    "        return True, function_call, usage\n",
    "    return False, \"Unable to search! Please try again later!\", usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(True, [{'name': 'Answer', 'parameters': {'answer': 'Kansas City Chiefs'}}], {'completion_tokens': 26, 'prompt_tokens': 645, 'total_tokens': 671})\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    asyncio.run(\n",
    "        searchGenAnswer(\n",
    "            llm,\n",
    "            \"gpt-4o\",\n",
    "            [{\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Who won the superbowl in 2020?\"\n",
    "            }],\n",
    "        )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(True, [{'name': 'Answer', 'parameters': {'answer': 'Manchester City'}}], {'completion_tokens': 21, 'prompt_tokens': 642, 'total_tokens': 663})\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    asyncio.run(\n",
    "        searchGenAnswer(llm, \"gpt-4o\", [{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Who won the UCL in 2023?\"\n",
    "        }])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(True, [{'name': 'Answer', 'parameters': {'answer': 'Real Madrid'}}], {'completion_tokens': 25, 'prompt_tokens': 721, 'total_tokens': 746})\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    asyncio.run(\n",
    "        searchGenAnswer(llm, \"gpt-4o\", [{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Who won the UCL in 2022?\"\n",
    "        }])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defined Function/Tool Call based on the available actions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFINED_TOOL_CALL = \"\"\"You are a helpful assistant as part of car infotainment system. The driver or passengers can ask you to perform specific tasks or can ask you about certain things.\n",
    "You can take the following actions\n",
    "* Interact with a call i.e. ACCEPT or REJECT a call.\n",
    "* Make a call.\n",
    "* Interact with Audio system i.e. Select and track to play, pause a track, or play a track.\n",
    "* Interact with navigation/map system i.e. start navigation to the location or update stops on the way.\n",
    "A user can even ask for multiple tasks to be done at once. The output of the task info should adhere to defined function schemas.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def callDefinedAction(llm: BaseLLM, model: str, messages: List[Dict]):\n",
    "    messages = [{\"role\": \"system\", \"content\": DEFINED_TOOL_CALL}] + messages\n",
    "    function_call_available, function_call, usage = await llm.__function_call__(\n",
    "        messages,\n",
    "        model,\n",
    "        available_domain_specific_tools,\n",
    "        seed=42,\n",
    "        temperature=0.2)\n",
    "    if function_call_available:\n",
    "        return function_call, usage\n",
    "    return None, usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([{'name': 'CallInteraction', 'parameters': {'interaction_type': 'REJECT'}}, {'name': 'SendMessage', 'parameters': {'app_name': 'Phone', 'meta': {'is_number': True, 'number': '+918878900', 'contact_name': None}, 'message_text': \"I'm driving cannot talk right now will catchup later.\"}}], {'completion_tokens': 101, 'prompt_tokens': 1530, 'total_tokens': 1631})\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    asyncio.run(\n",
    "        callDefinedAction(\n",
    "            llm,\n",
    "            \"gpt-4o\",\n",
    "            [\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": \"You are getting a call from +918878900\",\n",
    "                },\n",
    "                {\n",
    "                    \"role\":\n",
    "                    \"user\",\n",
    "                    \"content\":\n",
    "                    \"Reject the call and send message that I'm driving cannot talk right now will catchup later.\",\n",
    "                },\n",
    "            ],\n",
    "        )))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Completion with Mitigation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich.console import Console\n",
    "from rich.theme import Theme\n",
    "\n",
    "custom_theme = Theme({\n",
    "    \"info\": \"dim cyan\",\n",
    "    \"warning\": \"magenta\",\n",
    "    \"error\": \"bold red\",\n",
    "    \"prompt\": \"dim cyan\",\n",
    "    \"user_input\": \"bold green\",\n",
    "    \"assistant\": \"bold blue\",\n",
    "})\n",
    "console = Console(theme=custom_theme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "\n",
    "async def mitigateAndComplete(llm: BaseLLM, model: str, messages: List[Dict]):\n",
    "    st_time = time()\n",
    "    answer = -1\n",
    "    token_usage = {\n",
    "        \"completion_tokens\": 0,\n",
    "        \"prompt_tokens\": 0,\n",
    "        \"total_tokens\": 0\n",
    "    }\n",
    "\n",
    "    def updateUsage(usage):\n",
    "        for k, v in usage.items():\n",
    "            token_usage[k] += v\n",
    "\n",
    "    # console.print(\"User Input: \", messages[-1].get(\"content\"), style=\"user_input\")\n",
    "    reply_with_inherent_knowledge, usage = await canUseInherentKnowledge(\n",
    "        llm, model, messages)\n",
    "    updateUsage(usage)\n",
    "    if reply_with_inherent_knowledge == \"YES\":\n",
    "        # console.print(\"Replying with Inherent Knowledge\", style=\"info\")\n",
    "        answer, usage = await answerWithInherentKnowledge(llm, model, messages)\n",
    "        updateUsage(usage)\n",
    "        answer = answer\n",
    "        # if answer:\n",
    "        #     return answer\n",
    "        # return -1\n",
    "    elif reply_with_inherent_knowledge == \"NO\":\n",
    "        need_search, usage = await verifySearchRequired(llm, model, messages)\n",
    "        updateUsage(usage)\n",
    "        if need_search == \"YES\":\n",
    "            # console.print(\"Search to reply\", style=\"info\")\n",
    "            search_status, answer, usage = await searchGenAnswer(\n",
    "                llm, model, messages)\n",
    "            updateUsage(usage)\n",
    "            if search_status:\n",
    "                # return answer\n",
    "                answer = answer\n",
    "            # else:\n",
    "            #     # console.print(\"Unable to search\", style=\"info\")\n",
    "            #     # return -1\n",
    "        elif need_search == \"NO\":\n",
    "            # console.print(\"Calling defined Action\", style=\"info\")\n",
    "            defined_action, usage = await callDefinedAction(\n",
    "                llm, model, messages)\n",
    "            updateUsage(usage)\n",
    "            answer = defined_action if defined_action else -1\n",
    "            # return defined_action if defined_action else -1\n",
    "        # else:\n",
    "        #     return -1\n",
    "    # else:\n",
    "    #     return -1\n",
    "    latency = time() - st_time\n",
    "    return answer, token_usage, f\"{latency:.4f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">User Input:  Who was the captain of the Indian cricket team in </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2018</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">?</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mUser Input:  Who was the captain of the Indian cricket team in \u001b[0m\u001b[1;36m2018\u001b[0m\u001b[1;32m?\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('YES', [TopLogprob(token='YES', bytes=[89, 69, 83], logprob=-7.107425e-06)], {'completion_tokens': 1, 'prompt_tokens': 164, 'total_tokens': 165})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">Replying with Inherent Knowledge</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36mReplying with Inherent Knowledge\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">    [</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">        {</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">            </span><span style=\"color: #008000; text-decoration-color: #008000\">'name'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Answer'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">,</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">            </span><span style=\"color: #008000; text-decoration-color: #008000\">'parameters'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: {</span><span style=\"color: #008000; text-decoration-color: #008000\">'answer'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Virat Kohli was the captain of the Indian cricket team in 2018.'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">}</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">        }</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">    ],</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">    {</span><span style=\"color: #008000; text-decoration-color: #008000\">'completion_tokens'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">49</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'prompt_tokens'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">481</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'total_tokens'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">530</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">},</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'2.1260'</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34m(\u001b[0m\n",
       "\u001b[1;34m    \u001b[0m\u001b[1;34m[\u001b[0m\n",
       "\u001b[1;34m        \u001b[0m\u001b[1;34m{\u001b[0m\n",
       "\u001b[1;34m            \u001b[0m\u001b[32m'name'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[32m'Answer'\u001b[0m\u001b[1;34m,\u001b[0m\n",
       "\u001b[1;34m            \u001b[0m\u001b[32m'parameters'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[1;34m{\u001b[0m\u001b[32m'answer'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[32m'Virat Kohli was the captain of the Indian cricket team in 2018.'\u001b[0m\u001b[1;34m}\u001b[0m\n",
       "\u001b[1;34m        \u001b[0m\u001b[1;34m}\u001b[0m\n",
       "\u001b[1;34m    \u001b[0m\u001b[1;34m]\u001b[0m\u001b[1;34m,\u001b[0m\n",
       "\u001b[1;34m    \u001b[0m\u001b[1;34m{\u001b[0m\u001b[32m'completion_tokens'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[1;36m49\u001b[0m\u001b[1;34m, \u001b[0m\u001b[32m'prompt_tokens'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[1;36m481\u001b[0m\u001b[1;34m, \u001b[0m\u001b[32m'total_tokens'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[1;36m530\u001b[0m\u001b[1;34m}\u001b[0m\u001b[1;34m,\u001b[0m\n",
       "\u001b[1;34m    \u001b[0m\u001b[32m'2.1260'\u001b[0m\n",
       "\u001b[1;34m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "console.print(\n",
    "    asyncio.run(\n",
    "        mitigateAndComplete(\n",
    "            llm,\n",
    "            \"gpt-4o\",\n",
    "            [{\n",
    "                \"role\":\n",
    "                \"user\",\n",
    "                \"content\":\n",
    "                \"Who was the captain of the Indian cricket team in 2018?\",\n",
    "            }],\n",
    "        )),\n",
    "    style=\"assistant\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">User Input:  Send a message to contact Mom via WhatsApp that I won't be able to make for dinner</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mUser Input:  Send a message to contact Mom via WhatsApp that I won't be able to make for dinner\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('NO', [TopLogprob(token='NO', bytes=[78, 79], logprob=-2.1008714e-06)], {'completion_tokens': 1, 'prompt_tokens': 168, 'total_tokens': 169})\n",
      "SEARCH REQUIRED LABEL:  NO\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">Calling defined Action</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36mCalling defined Action\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">    [</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">        {</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">            </span><span style=\"color: #008000; text-decoration-color: #008000\">'name'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'SendMessage'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">,</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">            </span><span style=\"color: #008000; text-decoration-color: #008000\">'parameters'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: {</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">                </span><span style=\"color: #008000; text-decoration-color: #008000\">'app_name'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'WhatsApp'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">,</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">                </span><span style=\"color: #008000; text-decoration-color: #008000\">'meta'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: {</span><span style=\"color: #008000; text-decoration-color: #008000\">'is_number'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: </span><span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">False</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'number'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold; font-style: italic\">None</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'contact_name'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Mom'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">},</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">                </span><span style=\"color: #008000; text-decoration-color: #008000\">'message_text'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">\"I won't be able to make for dinner\"</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">            }</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">        }</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">    ],</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">    {</span><span style=\"color: #008000; text-decoration-color: #008000\">'completion_tokens'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">79</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'prompt_tokens'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1879</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'total_tokens'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1958</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">},</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'2.8123'</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34m(\u001b[0m\n",
       "\u001b[1;34m    \u001b[0m\u001b[1;34m[\u001b[0m\n",
       "\u001b[1;34m        \u001b[0m\u001b[1;34m{\u001b[0m\n",
       "\u001b[1;34m            \u001b[0m\u001b[32m'name'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[32m'SendMessage'\u001b[0m\u001b[1;34m,\u001b[0m\n",
       "\u001b[1;34m            \u001b[0m\u001b[32m'parameters'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[1;34m{\u001b[0m\n",
       "\u001b[1;34m                \u001b[0m\u001b[32m'app_name'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[32m'WhatsApp'\u001b[0m\u001b[1;34m,\u001b[0m\n",
       "\u001b[1;34m                \u001b[0m\u001b[32m'meta'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[1;34m{\u001b[0m\u001b[32m'is_number'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[1;3;91mFalse\u001b[0m\u001b[1;34m, \u001b[0m\u001b[32m'number'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[1;3;35mNone\u001b[0m\u001b[1;34m, \u001b[0m\u001b[32m'contact_name'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[32m'Mom'\u001b[0m\u001b[1;34m}\u001b[0m\u001b[1;34m,\u001b[0m\n",
       "\u001b[1;34m                \u001b[0m\u001b[32m'message_text'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[32m\"I won't be able to make for dinner\"\u001b[0m\n",
       "\u001b[1;34m            \u001b[0m\u001b[1;34m}\u001b[0m\n",
       "\u001b[1;34m        \u001b[0m\u001b[1;34m}\u001b[0m\n",
       "\u001b[1;34m    \u001b[0m\u001b[1;34m]\u001b[0m\u001b[1;34m,\u001b[0m\n",
       "\u001b[1;34m    \u001b[0m\u001b[1;34m{\u001b[0m\u001b[32m'completion_tokens'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[1;36m79\u001b[0m\u001b[1;34m, \u001b[0m\u001b[32m'prompt_tokens'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[1;36m1879\u001b[0m\u001b[1;34m, \u001b[0m\u001b[32m'total_tokens'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[1;36m1958\u001b[0m\u001b[1;34m}\u001b[0m\u001b[1;34m,\u001b[0m\n",
       "\u001b[1;34m    \u001b[0m\u001b[32m'2.8123'\u001b[0m\n",
       "\u001b[1;34m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "console.print(\n",
    "    asyncio.run(\n",
    "        mitigateAndComplete(\n",
    "            llm,\n",
    "            \"gpt-4o\",\n",
    "            [{\n",
    "                \"role\":\n",
    "                \"user\",\n",
    "                \"content\":\n",
    "                \"Send a message to contact Mom via WhatsApp that I won't be able to make for dinner\",\n",
    "            }],\n",
    "        )),\n",
    "    style=\"assistant\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">User Input:  Who won the UCL in </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2019</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">?</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mUser Input:  Who won the UCL in \u001b[0m\u001b[1;36m2019\u001b[0m\u001b[1;32m?\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('YES', [TopLogprob(token='YES', bytes=[89, 69, 83], logprob=-8.89548e-06)], {'completion_tokens': 1, 'prompt_tokens': 160, 'total_tokens': 161})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">Replying with Inherent Knowledge</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36mReplying with Inherent Knowledge\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">    [{</span><span style=\"color: #008000; text-decoration-color: #008000\">'name'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Answer'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'parameters'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: {</span><span style=\"color: #008000; text-decoration-color: #008000\">'answer'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Liverpool won the UEFA Champions League in 2019.'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">}}],</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">    {</span><span style=\"color: #008000; text-decoration-color: #008000\">'completion_tokens'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">34</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'prompt_tokens'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">473</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'total_tokens'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">507</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">},</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'1.4958'</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34m(\u001b[0m\n",
       "\u001b[1;34m    \u001b[0m\u001b[1;34m[\u001b[0m\u001b[1;34m{\u001b[0m\u001b[32m'name'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[32m'Answer'\u001b[0m\u001b[1;34m, \u001b[0m\u001b[32m'parameters'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[1;34m{\u001b[0m\u001b[32m'answer'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[32m'Liverpool won the UEFA Champions League in 2019.'\u001b[0m\u001b[1;34m}\u001b[0m\u001b[1;34m}\u001b[0m\u001b[1;34m]\u001b[0m\u001b[1;34m,\u001b[0m\n",
       "\u001b[1;34m    \u001b[0m\u001b[1;34m{\u001b[0m\u001b[32m'completion_tokens'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[1;36m34\u001b[0m\u001b[1;34m, \u001b[0m\u001b[32m'prompt_tokens'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[1;36m473\u001b[0m\u001b[1;34m, \u001b[0m\u001b[32m'total_tokens'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[1;36m507\u001b[0m\u001b[1;34m}\u001b[0m\u001b[1;34m,\u001b[0m\n",
       "\u001b[1;34m    \u001b[0m\u001b[32m'1.4958'\u001b[0m\n",
       "\u001b[1;34m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "console.print(\n",
    "    asyncio.run(\n",
    "        mitigateAndComplete(llm, \"gpt-4o\",\n",
    "                            [{\n",
    "                                \"role\": \"user\",\n",
    "                                \"content\": \"Who won the UCL in 2019?\"\n",
    "                            }])),\n",
    "    style=\"assistant\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">User Input:  Who won the UCL in </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2022</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">?</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mUser Input:  Who won the UCL in \u001b[0m\u001b[1;36m2022\u001b[0m\u001b[1;32m?\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('YES', [TopLogprob(token='YES', bytes=[89, 69, 83], logprob=-0.00010175513)], {'completion_tokens': 1, 'prompt_tokens': 160, 'total_tokens': 161})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">Replying with Inherent Knowledge</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36mReplying with Inherent Knowledge\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">    [{</span><span style=\"color: #008000; text-decoration-color: #008000\">'name'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Answer'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'parameters'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: {</span><span style=\"color: #008000; text-decoration-color: #008000\">'answer'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Real Madrid'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">}}],</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">    {</span><span style=\"color: #008000; text-decoration-color: #008000\">'completion_tokens'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'prompt_tokens'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">473</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'total_tokens'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">499</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">},</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'1.7661'</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34m(\u001b[0m\n",
       "\u001b[1;34m    \u001b[0m\u001b[1;34m[\u001b[0m\u001b[1;34m{\u001b[0m\u001b[32m'name'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[32m'Answer'\u001b[0m\u001b[1;34m, \u001b[0m\u001b[32m'parameters'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[1;34m{\u001b[0m\u001b[32m'answer'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[32m'Real Madrid'\u001b[0m\u001b[1;34m}\u001b[0m\u001b[1;34m}\u001b[0m\u001b[1;34m]\u001b[0m\u001b[1;34m,\u001b[0m\n",
       "\u001b[1;34m    \u001b[0m\u001b[1;34m{\u001b[0m\u001b[32m'completion_tokens'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[1;36m26\u001b[0m\u001b[1;34m, \u001b[0m\u001b[32m'prompt_tokens'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[1;36m473\u001b[0m\u001b[1;34m, \u001b[0m\u001b[32m'total_tokens'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[1;36m499\u001b[0m\u001b[1;34m}\u001b[0m\u001b[1;34m,\u001b[0m\n",
       "\u001b[1;34m    \u001b[0m\u001b[32m'1.7661'\u001b[0m\n",
       "\u001b[1;34m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "console.print(\n",
    "    asyncio.run(\n",
    "        mitigateAndComplete(llm, \"gpt-4o\",\n",
    "                            [{\n",
    "                                \"role\": \"user\",\n",
    "                                \"content\": \"Who won the UCL in 2022?\"\n",
    "                            }])),\n",
    "    style=\"assistant\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">User Input:  I'm driving I cannot talk right now reject it. Send him a message saying that</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mUser Input:  I'm driving I cannot talk right now reject it. Send him a message saying that\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('NO', [TopLogprob(token='NO', bytes=[78, 79], logprob=-3.392825e-05)], {'completion_tokens': 1, 'prompt_tokens': 181, 'total_tokens': 182})\n",
      "SEARCH REQUIRED LABEL:  NO\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">Calling defined Action</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36mCalling defined Action\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">    [</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">        {</span><span style=\"color: #008000; text-decoration-color: #008000\">'name'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'CallInteraction'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'parameters'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: {</span><span style=\"color: #008000; text-decoration-color: #008000\">'interaction_type'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'REJECT'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">}},</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">        {</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">            </span><span style=\"color: #008000; text-decoration-color: #008000\">'name'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'SendMessage'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">,</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">            </span><span style=\"color: #008000; text-decoration-color: #008000\">'parameters'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: {</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">                </span><span style=\"color: #008000; text-decoration-color: #008000\">'app_name'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Phone'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">,</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">                </span><span style=\"color: #008000; text-decoration-color: #008000\">'meta'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: {</span><span style=\"color: #008000; text-decoration-color: #008000\">'is_number'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: </span><span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">False</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'number'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold; font-style: italic\">None</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'contact_name'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'John Doe'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">},</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">                </span><span style=\"color: #008000; text-decoration-color: #008000\">'message_text'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">\"I'm driving I cannot talk right now\"</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">            }</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">        }</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">    ],</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">    {</span><span style=\"color: #008000; text-decoration-color: #008000\">'completion_tokens'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">104</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'prompt_tokens'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1918</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'total_tokens'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2022</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">},</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'3.0648'</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34m(\u001b[0m\n",
       "\u001b[1;34m    \u001b[0m\u001b[1;34m[\u001b[0m\n",
       "\u001b[1;34m        \u001b[0m\u001b[1;34m{\u001b[0m\u001b[32m'name'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[32m'CallInteraction'\u001b[0m\u001b[1;34m, \u001b[0m\u001b[32m'parameters'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[1;34m{\u001b[0m\u001b[32m'interaction_type'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[32m'REJECT'\u001b[0m\u001b[1;34m}\u001b[0m\u001b[1;34m}\u001b[0m\u001b[1;34m,\u001b[0m\n",
       "\u001b[1;34m        \u001b[0m\u001b[1;34m{\u001b[0m\n",
       "\u001b[1;34m            \u001b[0m\u001b[32m'name'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[32m'SendMessage'\u001b[0m\u001b[1;34m,\u001b[0m\n",
       "\u001b[1;34m            \u001b[0m\u001b[32m'parameters'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[1;34m{\u001b[0m\n",
       "\u001b[1;34m                \u001b[0m\u001b[32m'app_name'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[32m'Phone'\u001b[0m\u001b[1;34m,\u001b[0m\n",
       "\u001b[1;34m                \u001b[0m\u001b[32m'meta'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[1;34m{\u001b[0m\u001b[32m'is_number'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[1;3;91mFalse\u001b[0m\u001b[1;34m, \u001b[0m\u001b[32m'number'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[1;3;35mNone\u001b[0m\u001b[1;34m, \u001b[0m\u001b[32m'contact_name'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[32m'John Doe'\u001b[0m\u001b[1;34m}\u001b[0m\u001b[1;34m,\u001b[0m\n",
       "\u001b[1;34m                \u001b[0m\u001b[32m'message_text'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[32m\"I'm driving I cannot talk right now\"\u001b[0m\n",
       "\u001b[1;34m            \u001b[0m\u001b[1;34m}\u001b[0m\n",
       "\u001b[1;34m        \u001b[0m\u001b[1;34m}\u001b[0m\n",
       "\u001b[1;34m    \u001b[0m\u001b[1;34m]\u001b[0m\u001b[1;34m,\u001b[0m\n",
       "\u001b[1;34m    \u001b[0m\u001b[1;34m{\u001b[0m\u001b[32m'completion_tokens'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[1;36m104\u001b[0m\u001b[1;34m, \u001b[0m\u001b[32m'prompt_tokens'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[1;36m1918\u001b[0m\u001b[1;34m, \u001b[0m\u001b[32m'total_tokens'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[1;36m2022\u001b[0m\u001b[1;34m}\u001b[0m\u001b[1;34m,\u001b[0m\n",
       "\u001b[1;34m    \u001b[0m\u001b[32m'3.0648'\u001b[0m\n",
       "\u001b[1;34m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "console.print(\n",
    "    asyncio.run(\n",
    "        mitigateAndComplete(\n",
    "            llm,\n",
    "            \"gpt-4o\",\n",
    "            [\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": \"You have a call from contact name 'John Doe'\",\n",
    "                },\n",
    "                {\n",
    "                    \"role\":\n",
    "                    \"user\",\n",
    "                    \"content\":\n",
    "                    \"I'm driving I cannot talk right now reject it. Send him a message saying that\",\n",
    "                },\n",
    "            ],\n",
    "        )),\n",
    "    style=\"assistant\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation\n",
    "\n",
    "As we're already mitigating the possibility of hallucination in our completion only we just need to verify of the output we've received is part of the available function calls and adheres to the schema of that call.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CallInteraction(interaction_type='REJECT')"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CallInteraction.model_validate({\n",
    "    \"name\": \"CallInteraction\",\n",
    "    \"parameters\": {\n",
    "        \"interaction_type\": \"REJECT\"\n",
    "    }\n",
    "}[\"parameters\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import ValidationError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verifyFunctionNameAndSchema(function_call_output):\n",
    "    name2validation = {\n",
    "        \"CallInteraction\":\n",
    "        lambda fco: CallInteraction.model_validate(fco.get(\"parameters\")),\n",
    "        \"Answer\":\n",
    "        lambda fco: NonToolAnswer.model_validate(fco.get(\"parameters\")),\n",
    "        \"MakeCall\":\n",
    "        lambda fco: MakeCall.model_validate(fco.get(\"parameters\")),\n",
    "        \"SendMessage\":\n",
    "        lambda fco: SendMessage.model_validate(fco.get(\"parameters\")),\n",
    "        \"AudioInteraction\":\n",
    "        lambda fco: AudioInteraction.model_validate(fco.get(\"parameters\")),\n",
    "        \"MapInteraction\":\n",
    "        lambda fco: MapInteraction.model_validate(fco.get(\"parameters\")),\n",
    "    }\n",
    "    if function_call_output.get(\"name\") in name2validation:\n",
    "        try:\n",
    "            name2validation[function_call_output.get(\"name\")](\n",
    "                function_call_output)\n",
    "            return True, \"\"\n",
    "        except ValidationError as err:\n",
    "            return False, str(err)\n",
    "    else:\n",
    "        return False, \"Function Call Not Available!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mitigate + Complete + Validate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def mitigateCompleteValidate(llm: BaseLLM, model: str,\n",
    "                                   messages: List[Dict]):\n",
    "    output = -1\n",
    "    function_calls, token_usage, latency = await mitigateAndComplete(\n",
    "        llm, model, messages)\n",
    "    vst = time()\n",
    "    # if not function_calls or function_calls == -1:\n",
    "    #     return -1\n",
    "    if all([\n",
    "            verifyFunctionNameAndSchema(function_call)[0]\n",
    "            for function_call in function_calls\n",
    "    ]):\n",
    "        # return function_calls\n",
    "        output = function_calls\n",
    "    # else:\n",
    "    #     return -1\n",
    "    latency = f\"{(time() - vst + float(latency)):.4f}\"\n",
    "    return output, token_usage, latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">User Input:  I'm driving I cannot talk right now reject it. Send him a message saying that</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mUser Input:  I'm driving I cannot talk right now reject it. Send him a message saying that\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('NO', [TopLogprob(token='NO', bytes=[78, 79], logprob=-8.89548e-06)], {'completion_tokens': 1, 'prompt_tokens': 181, 'total_tokens': 182})\n",
      "SEARCH REQUIRED LABEL:  NO\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">Calling defined Action</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36mCalling defined Action\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">    [</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">        {</span><span style=\"color: #008000; text-decoration-color: #008000\">'name'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'CallInteraction'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'parameters'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: {</span><span style=\"color: #008000; text-decoration-color: #008000\">'interaction_type'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'REJECT'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">}},</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">        {</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">            </span><span style=\"color: #008000; text-decoration-color: #008000\">'name'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'SendMessage'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">,</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">            </span><span style=\"color: #008000; text-decoration-color: #008000\">'parameters'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: {</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">                </span><span style=\"color: #008000; text-decoration-color: #008000\">'app_name'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Phone'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">,</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">                </span><span style=\"color: #008000; text-decoration-color: #008000\">'meta'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: {</span><span style=\"color: #008000; text-decoration-color: #008000\">'is_number'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: </span><span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">False</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'number'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold; font-style: italic\">None</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'contact_name'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'John Doe'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">},</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">                </span><span style=\"color: #008000; text-decoration-color: #008000\">'message_text'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">\"I'm driving I cannot talk right now\"</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">            }</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">        }</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">    ],</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">    {</span><span style=\"color: #008000; text-decoration-color: #008000\">'completion_tokens'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">98</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'prompt_tokens'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1918</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'total_tokens'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2016</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">},</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'3.0177'</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34m(\u001b[0m\n",
       "\u001b[1;34m    \u001b[0m\u001b[1;34m[\u001b[0m\n",
       "\u001b[1;34m        \u001b[0m\u001b[1;34m{\u001b[0m\u001b[32m'name'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[32m'CallInteraction'\u001b[0m\u001b[1;34m, \u001b[0m\u001b[32m'parameters'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[1;34m{\u001b[0m\u001b[32m'interaction_type'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[32m'REJECT'\u001b[0m\u001b[1;34m}\u001b[0m\u001b[1;34m}\u001b[0m\u001b[1;34m,\u001b[0m\n",
       "\u001b[1;34m        \u001b[0m\u001b[1;34m{\u001b[0m\n",
       "\u001b[1;34m            \u001b[0m\u001b[32m'name'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[32m'SendMessage'\u001b[0m\u001b[1;34m,\u001b[0m\n",
       "\u001b[1;34m            \u001b[0m\u001b[32m'parameters'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[1;34m{\u001b[0m\n",
       "\u001b[1;34m                \u001b[0m\u001b[32m'app_name'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[32m'Phone'\u001b[0m\u001b[1;34m,\u001b[0m\n",
       "\u001b[1;34m                \u001b[0m\u001b[32m'meta'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[1;34m{\u001b[0m\u001b[32m'is_number'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[1;3;91mFalse\u001b[0m\u001b[1;34m, \u001b[0m\u001b[32m'number'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[1;3;35mNone\u001b[0m\u001b[1;34m, \u001b[0m\u001b[32m'contact_name'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[32m'John Doe'\u001b[0m\u001b[1;34m}\u001b[0m\u001b[1;34m,\u001b[0m\n",
       "\u001b[1;34m                \u001b[0m\u001b[32m'message_text'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[32m\"I'm driving I cannot talk right now\"\u001b[0m\n",
       "\u001b[1;34m            \u001b[0m\u001b[1;34m}\u001b[0m\n",
       "\u001b[1;34m        \u001b[0m\u001b[1;34m}\u001b[0m\n",
       "\u001b[1;34m    \u001b[0m\u001b[1;34m]\u001b[0m\u001b[1;34m,\u001b[0m\n",
       "\u001b[1;34m    \u001b[0m\u001b[1;34m{\u001b[0m\u001b[32m'completion_tokens'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[1;36m98\u001b[0m\u001b[1;34m, \u001b[0m\u001b[32m'prompt_tokens'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[1;36m1918\u001b[0m\u001b[1;34m, \u001b[0m\u001b[32m'total_tokens'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[1;36m2016\u001b[0m\u001b[1;34m}\u001b[0m\u001b[1;34m,\u001b[0m\n",
       "\u001b[1;34m    \u001b[0m\u001b[32m'3.0177'\u001b[0m\n",
       "\u001b[1;34m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "console.print(\n",
    "    asyncio.run(\n",
    "        mitigateCompleteValidate(\n",
    "            llm,\n",
    "            \"gpt-4o\",\n",
    "            [\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": \"You have a call from contact name 'John Doe'\",\n",
    "                },\n",
    "                {\n",
    "                    \"role\":\n",
    "                    \"user\",\n",
    "                    \"content\":\n",
    "                    \"I'm driving I cannot talk right now reject it. Send him a message saying that\",\n",
    "                },\n",
    "            ],\n",
    "        )),\n",
    "    style=\"assistant\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">    [{</span><span style=\"color: #008000; text-decoration-color: #008000\">'name'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Answer'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'parameters'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: {</span><span style=\"color: #008000; text-decoration-color: #008000\">'answer'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Real Madrid won the UEFA Champions League in 2022.'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">}}],</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">    {</span><span style=\"color: #008000; text-decoration-color: #008000\">'completion_tokens'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'prompt_tokens'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">473</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'total_tokens'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">515</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">},</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'2.5610'</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34m(\u001b[0m\n",
       "\u001b[1;34m    \u001b[0m\u001b[1;34m[\u001b[0m\u001b[1;34m{\u001b[0m\u001b[32m'name'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[32m'Answer'\u001b[0m\u001b[1;34m, \u001b[0m\u001b[32m'parameters'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[1;34m{\u001b[0m\u001b[32m'answer'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[32m'Real Madrid won the UEFA Champions League in 2022.'\u001b[0m\u001b[1;34m}\u001b[0m\u001b[1;34m}\u001b[0m\u001b[1;34m]\u001b[0m\u001b[1;34m,\u001b[0m\n",
       "\u001b[1;34m    \u001b[0m\u001b[1;34m{\u001b[0m\u001b[32m'completion_tokens'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;34m, \u001b[0m\u001b[32m'prompt_tokens'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[1;36m473\u001b[0m\u001b[1;34m, \u001b[0m\u001b[32m'total_tokens'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[1;36m515\u001b[0m\u001b[1;34m}\u001b[0m\u001b[1;34m,\u001b[0m\n",
       "\u001b[1;34m    \u001b[0m\u001b[32m'2.5610'\u001b[0m\n",
       "\u001b[1;34m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "console.print(\n",
    "    asyncio.run(\n",
    "        mitigateCompleteValidate(llm, \"gpt-4o\",\n",
    "                                 [{\n",
    "                                     \"role\": \"user\",\n",
    "                                     \"content\": \"Who won the UCL in 2022?\"\n",
    "                                 }])),\n",
    "    style=\"assistant\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">User Input:  Who won the UCL in </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2023</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">?</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mUser Input:  Who won the UCL in \u001b[0m\u001b[1;36m2023\u001b[0m\u001b[1;32m?\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('NO', [TopLogprob(token='NO', bytes=[78, 79], logprob=-0.28119066)], {'completion_tokens': 1, 'prompt_tokens': 160, 'total_tokens': 161})\n",
      "SEARCH REQUIRED LABEL:  YES\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">Search to reply</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36mSearch to reply\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">    [{</span><span style=\"color: #008000; text-decoration-color: #008000\">'name'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Answer'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'parameters'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: {</span><span style=\"color: #008000; text-decoration-color: #008000\">'answer'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Manchester City'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">}}],</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">    {</span><span style=\"color: #008000; text-decoration-color: #008000\">'completion_tokens'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'prompt_tokens'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">989</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'total_tokens'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1017</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">},</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'4.7292'</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34m(\u001b[0m\n",
       "\u001b[1;34m    \u001b[0m\u001b[1;34m[\u001b[0m\u001b[1;34m{\u001b[0m\u001b[32m'name'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[32m'Answer'\u001b[0m\u001b[1;34m, \u001b[0m\u001b[32m'parameters'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[1;34m{\u001b[0m\u001b[32m'answer'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[32m'Manchester City'\u001b[0m\u001b[1;34m}\u001b[0m\u001b[1;34m}\u001b[0m\u001b[1;34m]\u001b[0m\u001b[1;34m,\u001b[0m\n",
       "\u001b[1;34m    \u001b[0m\u001b[1;34m{\u001b[0m\u001b[32m'completion_tokens'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;34m, \u001b[0m\u001b[32m'prompt_tokens'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[1;36m989\u001b[0m\u001b[1;34m, \u001b[0m\u001b[32m'total_tokens'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[1;36m1017\u001b[0m\u001b[1;34m}\u001b[0m\u001b[1;34m,\u001b[0m\n",
       "\u001b[1;34m    \u001b[0m\u001b[32m'4.7292'\u001b[0m\n",
       "\u001b[1;34m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "console.print(\n",
    "    asyncio.run(\n",
    "        mitigateCompleteValidate(llm, \"gpt-4o\",\n",
    "                                 [{\n",
    "                                     \"role\": \"user\",\n",
    "                                     \"content\": \"Who won the UCL in 2023?\"\n",
    "                                 }])),\n",
    "    style=\"assistant\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">User Input:  Who won the UCL in </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">?</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mUser Input:  Who won the UCL in \u001b[0m\u001b[1;36m2024\u001b[0m\u001b[1;32m?\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('NO', [TopLogprob(token='NO', bytes=[78, 79], logprob=-6.869018e-06)], {'completion_tokens': 1, 'prompt_tokens': 160, 'total_tokens': 161})\n",
      "SEARCH REQUIRED LABEL:  YES\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">Search to reply</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36mSearch to reply\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">    [</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">        {</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">            </span><span style=\"color: #008000; text-decoration-color: #008000\">'name'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Answer'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">,</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">            </span><span style=\"color: #008000; text-decoration-color: #008000\">'parameters'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: {</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">                </span><span style=\"color: #008000; text-decoration-color: #008000\">'answer'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'The search results do not provide information on the winner of the 2024 UEFA Champions </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">League.'</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">            }</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">        }</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">    ],</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">    {</span><span style=\"color: #008000; text-decoration-color: #008000\">'completion_tokens'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">43</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'prompt_tokens'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1017</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'total_tokens'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1060</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">},</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'4.1546'</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34m(\u001b[0m\n",
       "\u001b[1;34m    \u001b[0m\u001b[1;34m[\u001b[0m\n",
       "\u001b[1;34m        \u001b[0m\u001b[1;34m{\u001b[0m\n",
       "\u001b[1;34m            \u001b[0m\u001b[32m'name'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[32m'Answer'\u001b[0m\u001b[1;34m,\u001b[0m\n",
       "\u001b[1;34m            \u001b[0m\u001b[32m'parameters'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[1;34m{\u001b[0m\n",
       "\u001b[1;34m                \u001b[0m\u001b[32m'answer'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[32m'The search results do not provide information on the winner of the 2024 UEFA Champions \u001b[0m\n",
       "\u001b[32mLeague.'\u001b[0m\n",
       "\u001b[1;34m            \u001b[0m\u001b[1;34m}\u001b[0m\n",
       "\u001b[1;34m        \u001b[0m\u001b[1;34m}\u001b[0m\n",
       "\u001b[1;34m    \u001b[0m\u001b[1;34m]\u001b[0m\u001b[1;34m,\u001b[0m\n",
       "\u001b[1;34m    \u001b[0m\u001b[1;34m{\u001b[0m\u001b[32m'completion_tokens'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[1;36m43\u001b[0m\u001b[1;34m, \u001b[0m\u001b[32m'prompt_tokens'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[1;36m1017\u001b[0m\u001b[1;34m, \u001b[0m\u001b[32m'total_tokens'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[1;36m1060\u001b[0m\u001b[1;34m}\u001b[0m\u001b[1;34m,\u001b[0m\n",
       "\u001b[1;34m    \u001b[0m\u001b[32m'4.1546'\u001b[0m\n",
       "\u001b[1;34m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "console.print(\n",
    "    asyncio.run(\n",
    "        mitigateCompleteValidate(llm, \"gpt-4o\",\n",
    "                                 [{\n",
    "                                     \"role\": \"user\",\n",
    "                                     \"content\": \"Who won the UCL in 2024?\"\n",
    "                                 }])),\n",
    "    style=\"assistant\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">User Input:  Navigate to Church Street, Bangalore</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mUser Input:  Navigate to Church Street, Bangalore\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('NO', [TopLogprob(token='NO', bytes=[78, 79], logprob=-4.4537377e-05)], {'completion_tokens': 1, 'prompt_tokens': 156, 'total_tokens': 157})\n",
      "SEARCH REQUIRED LABEL:  NO\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">Calling defined Action</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36mCalling defined Action\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">    [{</span><span style=\"color: #008000; text-decoration-color: #008000\">'name'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'MapInteraction'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'parameters'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: {</span><span style=\"color: #008000; text-decoration-color: #008000\">'action'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Start'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'is_update'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: </span><span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">False</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'stop'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold; font-style: italic\">None</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">}}],</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">    {</span><span style=\"color: #008000; text-decoration-color: #008000\">'completion_tokens'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">46</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'prompt_tokens'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1843</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'total_tokens'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1889</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">},</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'2.1477'</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34m(\u001b[0m\n",
       "\u001b[1;34m    \u001b[0m\u001b[1;34m[\u001b[0m\u001b[1;34m{\u001b[0m\u001b[32m'name'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[32m'MapInteraction'\u001b[0m\u001b[1;34m, \u001b[0m\u001b[32m'parameters'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[1;34m{\u001b[0m\u001b[32m'action'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[32m'Start'\u001b[0m\u001b[1;34m, \u001b[0m\u001b[32m'is_update'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[1;3;91mFalse\u001b[0m\u001b[1;34m, \u001b[0m\u001b[32m'stop'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[1;3;35mNone\u001b[0m\u001b[1;34m}\u001b[0m\u001b[1;34m}\u001b[0m\u001b[1;34m]\u001b[0m\u001b[1;34m,\u001b[0m\n",
       "\u001b[1;34m    \u001b[0m\u001b[1;34m{\u001b[0m\u001b[32m'completion_tokens'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[1;36m46\u001b[0m\u001b[1;34m, \u001b[0m\u001b[32m'prompt_tokens'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[1;36m1843\u001b[0m\u001b[1;34m, \u001b[0m\u001b[32m'total_tokens'\u001b[0m\u001b[1;34m: \u001b[0m\u001b[1;36m1889\u001b[0m\u001b[1;34m}\u001b[0m\u001b[1;34m,\u001b[0m\n",
       "\u001b[1;34m    \u001b[0m\u001b[32m'2.1477'\u001b[0m\n",
       "\u001b[1;34m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "console.print(\n",
    "    asyncio.run(\n",
    "        mitigateCompleteValidate(\n",
    "            llm,\n",
    "            \"gpt-4o\",\n",
    "            [{\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Navigate to Church Street, Bangalore\"\n",
    "            }],\n",
    "        )),\n",
    "    style=\"assistant\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM-as-a-Judge\n",
    "\n",
    "We're validating the function call against its availability and the schema generated for the function call against what we've defined for it.\n",
    "\n",
    "Now for a set of multi-turn instruction let's use the **LLM-as-a-Judge** approach to verify the quality of the response on a scale of 0 to 4.\n",
    "\n",
    "We'll use the `gpt-4-turbo` model as the Judge.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge_llm = OpenAILLM(model=\"gpt-4-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "## judge output schema\n",
    "\n",
    "\n",
    "class JudgeOutput(BaseModel):\n",
    "    evaluation: str = Field(\n",
    "        ...,\n",
    "        description=\n",
    "        \"Your rationale for the rating, explaining how well the function call aligns with the user's request\",\n",
    "    )\n",
    "    rating: int = Field(\n",
    "        ...,\n",
    "        description=\"Your rating, as a number between 1 and 4.\",\n",
    "        ge=1,\n",
    "        le=4)\n",
    "\n",
    "\n",
    "judge_functions = [{\n",
    "    \"name\": \"JudgeSystemGeneratedResponse\",\n",
    "    \"description\":\n",
    "    \"Provide your score for the system generated output in context of the user messages\",\n",
    "    \"parameters\": JudgeOutput.model_json_schema(),\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "JUDGE_PROMPT = \"\"\"You will be provided with a system generated response for a set of user messages in the form of function calls that the system proposes to handle the user's request.\n",
    "Your task is to evaluate how effectively the system generated response meets the user's needs as expressed by the user.\n",
    "\n",
    "The responses could be functions calls for various actions such as 'MakeCall', 'CallInteraction', 'SendMessage', 'AudioInteraction', 'MapInteraction', and 'Answer'.\n",
    "Each function call will have parameters detailing the action to be taken.\n",
    "\n",
    "Here is the scale you should use to build your answer:\n",
    "1: The response is completely inappropriate: it does not address the user's request at all or is grossly incorrect.\n",
    "2: The response is partially appropriate: it addresses some aspects of the user's request but misses other important aspects.\n",
    "3: The response is mostly appropriate: it adequately addresses the user's request but could include more precise parameters or additional relevant actions.\n",
    "4: The response is excellent: it perfectly matches the user's request and includes all necessary details and parameters.\n",
    "\n",
    "Apart from scoring you also need to provide you rationale behind the scoring as mentioned in the function schema.\n",
    "Always output between the <functioncall></functioncall> block.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def judgeResponse(\n",
    "    llm: BaseLLM,\n",
    "    model: str,\n",
    "    messages: List[Dict],\n",
    "    system_generated_response: List[Dict],\n",
    "):\n",
    "    st_time = time()\n",
    "    messages = ([{\n",
    "        \"role\": \"system\",\n",
    "        \"content\": JUDGE_PROMPT\n",
    "    }] + messages + [{\n",
    "        \"role\":\n",
    "        \"assistant\",\n",
    "        \"content\":\n",
    "        f\"System Generated Response: '{system_generated_response}'\",\n",
    "    }])\n",
    "    fc_available, function_call, usage = await llm.__function_call__(\n",
    "        messages, model, judge_functions)\n",
    "    if not fc_available:\n",
    "        return {\"rating\": 0, \"evaluation\": \"Unable to rank!\"}\n",
    "    ranking_parameters = function_call[0].get(\"parameters\")\n",
    "    latency = time() - st_time\n",
    "    return ranking_parameters, usage, f\"{latency:.4f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "    <span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'JudgeSystemGeneratedResponse'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'parameters'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'rating'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'evaluation'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"The response initiates a map interaction with a start action, but does not specify </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the destination, which is essential for navigation. It misses the crucial aspect of the location details ('Church </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Street, Bangalore') necessary for the navigation request.\"</span>\n",
       "            <span style=\"font-weight: bold\">}</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'completion_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">72</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'prompt_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">635</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'total_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">707</span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\n",
       "    \u001b[3;92mTrue\u001b[0m,\n",
       "    \u001b[1m[\u001b[0m\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'name'\u001b[0m: \u001b[32m'JudgeSystemGeneratedResponse'\u001b[0m,\n",
       "            \u001b[32m'parameters'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                \u001b[32m'rating'\u001b[0m: \u001b[1;36m2\u001b[0m,\n",
       "                \u001b[32m'evaluation'\u001b[0m: \u001b[32m\"The response initiates a map interaction with a start action, but does not specify \u001b[0m\n",
       "\u001b[32mthe destination, which is essential for navigation. It misses the crucial aspect of the location details \u001b[0m\u001b[32m(\u001b[0m\u001b[32m'Church \u001b[0m\n",
       "\u001b[32mStreet, Bangalore'\u001b[0m\u001b[32m)\u001b[0m\u001b[32m necessary for the navigation request.\"\u001b[0m\n",
       "            \u001b[1m}\u001b[0m\n",
       "        \u001b[1m}\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[1m{\u001b[0m\u001b[32m'completion_tokens'\u001b[0m: \u001b[1;36m72\u001b[0m, \u001b[32m'prompt_tokens'\u001b[0m: \u001b[1;36m635\u001b[0m, \u001b[32m'total_tokens'\u001b[0m: \u001b[1;36m707\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": JUDGE_PROMPT\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Navigate to Church Street, Bangalore\"\n",
    "    },\n",
    "]\n",
    "messages += [{\n",
    "    \"role\":\n",
    "    \"assistant\",\n",
    "    \"content\":\n",
    "    \"\"\"System Generated Response: [{'name': 'MapInteraction', 'parameters': {'action': 'Start', 'is_update': False, 'stop': None}}]\"\"\",\n",
    "}]\n",
    "output = asyncio.run(\n",
    "    judge_llm.__function_call__(messages, \"gpt-4-turbo\", judge_functions))\n",
    "console.print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "    <span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'JudgeSystemGeneratedResponse'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'parameters'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'rating'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'evaluation'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"The response is partially appropriate because it initiates a map interaction, which </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">aligns with the users request for navigation. However, it lacks critical details such as the destination ('Church </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Street, Bangalore'), making it incomplete and not wholly useful for achieving the users navigation needs.\"</span>\n",
       "            <span style=\"font-weight: bold\">}</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'completion_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">78</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'prompt_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">622</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'total_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">700</span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\n",
       "    \u001b[3;92mTrue\u001b[0m,\n",
       "    \u001b[1m[\u001b[0m\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'name'\u001b[0m: \u001b[32m'JudgeSystemGeneratedResponse'\u001b[0m,\n",
       "            \u001b[32m'parameters'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                \u001b[32m'rating'\u001b[0m: \u001b[1;36m2\u001b[0m,\n",
       "                \u001b[32m'evaluation'\u001b[0m: \u001b[32m\"The response is partially appropriate because it initiates a map interaction, which \u001b[0m\n",
       "\u001b[32maligns with the users request for navigation. However, it lacks critical details such as the destination \u001b[0m\u001b[32m(\u001b[0m\u001b[32m'Church \u001b[0m\n",
       "\u001b[32mStreet, Bangalore'\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, making it incomplete and not wholly useful for achieving the users navigation needs.\"\u001b[0m\n",
       "            \u001b[1m}\u001b[0m\n",
       "        \u001b[1m}\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[1m{\u001b[0m\u001b[32m'completion_tokens'\u001b[0m: \u001b[1;36m78\u001b[0m, \u001b[32m'prompt_tokens'\u001b[0m: \u001b[1;36m622\u001b[0m, \u001b[32m'total_tokens'\u001b[0m: \u001b[1;36m700\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": JUDGE_PROMPT\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Navigate to Church Street, Bangalore\"\n",
    "    },\n",
    "]\n",
    "messages += [{\n",
    "    \"role\":\n",
    "    \"assistant\",\n",
    "    \"content\":\n",
    "    \"\"\"System Generated Response: [{'name': 'MapInteraction', 'parameters': {'action': 'Start', 'is_update': False, 'stop': None}}]\"\"\",\n",
    "}]\n",
    "output = asyncio.run(\n",
    "    judge_llm.__function_call__(messages, \"gpt-4-turbo\", judge_functions))\n",
    "console.print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">    </span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">        </span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'rating'</span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">: </span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">4</span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">,</span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">        </span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'evaluation'</span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">: </span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">\"The system's response is excellent as it precisely addresses the user's request to reject </span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">the call and send an appropriate message while driving. Both the 'CallInteraction' with 'REJECT' and 'SendMessage' </span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">actions are correctly aligned with the user's instructions and the intended recipient.\"</span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">    </span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">}</span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">,</span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">    </span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">{</span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'completion_tokens'</span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">: </span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">87</span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">, </span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'prompt_tokens'</span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">: </span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">707</span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">, </span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'total_tokens'</span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">: </span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">794</span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">}</span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">,</span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">    </span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'2.9927'</span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;2;36m(\u001b[0m\n",
       "\u001b[2;36m    \u001b[0m\u001b[1;2;36m{\u001b[0m\n",
       "\u001b[2;36m        \u001b[0m\u001b[2;32m'rating'\u001b[0m\u001b[2;36m: \u001b[0m\u001b[1;2;36m4\u001b[0m\u001b[2;36m,\u001b[0m\n",
       "\u001b[2;36m        \u001b[0m\u001b[2;32m'evaluation'\u001b[0m\u001b[2;36m: \u001b[0m\u001b[2;32m\"The system's response is excellent as it precisely addresses the user's request to reject \u001b[0m\n",
       "\u001b[2;32mthe call and send an appropriate message while driving. Both the 'CallInteraction' with 'REJECT' and 'SendMessage' \u001b[0m\n",
       "\u001b[2;32mactions are correctly aligned with the user's instructions and the intended recipient.\"\u001b[0m\n",
       "\u001b[2;36m    \u001b[0m\u001b[1;2;36m}\u001b[0m\u001b[2;36m,\u001b[0m\n",
       "\u001b[2;36m    \u001b[0m\u001b[1;2;36m{\u001b[0m\u001b[2;32m'completion_tokens'\u001b[0m\u001b[2;36m: \u001b[0m\u001b[1;2;36m87\u001b[0m\u001b[2;36m, \u001b[0m\u001b[2;32m'prompt_tokens'\u001b[0m\u001b[2;36m: \u001b[0m\u001b[1;2;36m707\u001b[0m\u001b[2;36m, \u001b[0m\u001b[2;32m'total_tokens'\u001b[0m\u001b[2;36m: \u001b[0m\u001b[1;2;36m794\u001b[0m\u001b[1;2;36m}\u001b[0m\u001b[2;36m,\u001b[0m\n",
       "\u001b[2;36m    \u001b[0m\u001b[2;32m'2.9927'\u001b[0m\n",
       "\u001b[1;2;36m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "op = asyncio.run(\n",
    "    judgeResponse(\n",
    "        judge_llm,\n",
    "        \"gpt-4-turbo\",\n",
    "        [\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"You have a call from contact name 'John Doe'\",\n",
    "            },\n",
    "            {\n",
    "                \"role\":\n",
    "                \"user\",\n",
    "                \"content\":\n",
    "                \"I'm driving I cannot talk right now reject it. Send him a message saying that\",\n",
    "            },\n",
    "        ],\n",
    "        \"\"\"[\n",
    "    {'name': 'CallInteraction', 'parameters': {'interaction_type': 'REJECT'}},\n",
    "    {\n",
    "        'name': 'SendMessage',\n",
    "        'parameters': {\n",
    "            'app_name': 'Phone',\n",
    "            'meta': {'is_number': False, 'number': None, 'contact_name': 'John Doe'},\n",
    "            'message_text': \"I'm driving I cannot talk right now\"\n",
    "        }\n",
    "    }\n",
    "]\"\"\",\n",
    "    ))\n",
    "console.print(op, style=\"prompt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation with LLMJudge\n",
    "\n",
    "There are $14$ multi-turn conversations available in `test_dataset/conversations.json` file. We'll be testing the system response returned by the `mitigateCompleteValidate` function using the `judgeResponse` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "conversations = json.loads(open(\"../test_dataset/conversations.json\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(conversations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "async def evaluate(conversations):\n",
    "    ratings = []\n",
    "    mitigate_complete_validate_token_usage = []\n",
    "    mitigate_complete_validate_latency = 0\n",
    "    rating_token_usage = []\n",
    "    rating_latency = 0\n",
    "    outputs = []\n",
    "    for _, conversation in enumerate(tqdm(conversations)):\n",
    "        try:\n",
    "            output, token_usage, latency = await mitigateCompleteValidate(\n",
    "                llm, \"gpt-4o\", conversation)\n",
    "            outputs.append(output)\n",
    "            mitigate_complete_validate_latency += float(latency)\n",
    "            mitigate_complete_validate_token_usage.append(token_usage)\n",
    "            if not output == -1:\n",
    "                rating, usage, latency = await judgeResponse(\n",
    "                    judge_llm, \"gpt-4-turbo\", conversation, output)\n",
    "                rating_latency += float(latency)\n",
    "                rating_token_usage.append(usage)\n",
    "                ratings.append(rating)\n",
    "            else:\n",
    "                ratings.append({\"ranking\": 0, \"evaluation\": \"\"})\n",
    "        except Exception as err:\n",
    "            pass\n",
    "    return (\n",
    "        ratings,\n",
    "        mitigate_complete_validate_token_usage,\n",
    "        mitigate_complete_validate_latency,\n",
    "        rating_token_usage,\n",
    "        rating_latency,\n",
    "        outputs,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d465cdfe07c4dcc800adb341739620c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluation_output = asyncio.run(evaluate(conversations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    ratings,\n",
    "    mitigate_complete_validate_token_usage,\n",
    "    mitigate_complete_validate_latency,\n",
    "    rating_token_usage,\n",
    "    rating_latency,\n",
    "    outputs,\n",
    ") = evaluation_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_report = []\n",
    "for ix in range(len(ratings)):\n",
    "    combined_report.append({\n",
    "        \"input\":\n",
    "        conversations[ix],\n",
    "        \"system_response\":\n",
    "        outputs[ix],\n",
    "        \"rating\":\n",
    "        ratings[ix],\n",
    "        \"token_usage\":\n",
    "        mitigate_complete_validate_token_usage[ix],\n",
    "    })\n",
    "average_rating = sum([rating.get(\"rating\")\n",
    "                      for rating in ratings]) / len(ratings)\n",
    "combined_report = {\n",
    "    \"report\":\n",
    "    combined_report,\n",
    "    \"average_rating\":\n",
    "    average_rating,\n",
    "    \"total_time_for_generating_system_responses\":\n",
    "    mitigate_complete_validate_latency,\n",
    "    \"average_time_for_generating_system_responses\":\n",
    "    mitigate_complete_validate_latency / len(outputs),\n",
    "    \"total_time_for_evaluating\":\n",
    "    rating_latency,\n",
    "    \"average_rating_time\":\n",
    "    rating_latency / len(ratings),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./evaluation_report.json\", \"w\") as fp:\n",
    "    json.dump(combined_report, fp, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "claudetools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
